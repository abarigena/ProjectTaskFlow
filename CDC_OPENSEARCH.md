# Интеграция OpenSearch и синхронизация с помощью CDC

Это руководство описывает процесс настройки синхронизации данных из **PostgreSQL** в **OpenSearch** с использованием **Change Data Capture (CDC)**. Мы используем **Debezium** как инструмент для захвата изменений.

---

### Шаг 1: Подготовка окружения в `docker-compose.yml`

Фундамент нашей системы — это контейнеры, определённые в `docker-compose.yml`. Каждый сервис играет ключевую роль:

1.  **PostgreSQL с `wal_level=logical`**
    -   **Конфигурация**: `command: ["postgres", "-c", "wal_level=logical"]`
    -   **Почему это важно**: Это **самая критичная настройка** для PostgreSQL. Debezium работает, читая журнал предзаписи (Write-Ahead Log, WAL). Уровень `logical` предоставляет детализированную информацию об изменениях на уровне строк (что было создано, обновлено или удалено). Без этой настройки Debezium не сможет захватывать изменения.

2.  **Debezium (`debezium/connect:2.4`)**
    -   **Что это**: Готовый образ Kafka Connect с предустановленным коннектором Debezium для PostgreSQL. Он выступает в роли моста между базой данных и Kafka.
    -   **Как работает**: Подключается к PostgreSQL, "слушает" WAL, преобразует изменения в структурированные JSON-события и отправляет их в топики Kafka.

3.  **OpenSearch (`opensearchproject/opensearch`)**
    -   **Что это**: Наш поисковый движок. Он хранит денормализованные данные для сверхбыстрого полнотекстового поиска и выполнения аналитических запросов.

---

### Шаг 2: Конфигурация коннектора Debezium (`debezium-postgres-connector.json`)

Этот JSON-файл — это "мозг" нашего коннектора. Он говорит Debezium, *что* и *как* отслеживать.

-   `"table.include.list": "public.tasks,public.comments,public.projects,public.users"`
    -   Определяет "белый список" таблиц, за изменениями в которых мы хотим следить.

-   `"snapshot.mode": "initial"`
    -   **Почему это важно**: Эта настройка приказывает Debezium при первом запуске сделать "снимок" всех существующих данных в отслеживаемых таблицах. Он считывает все строки и отправляет их в Kafka как события создания (`"op": "r"`). Это гарантирует, что OpenSearch будет содержать **полную копию данных**, а не только те, что изменились после запуска коннектора.

-   **Трансформация топиков с помощью `RegexRouter`**
    -   **Проблема**: По умолчанию Debezium создаёт длинные и неудобные имена топиков, например, `taskflow.public.users`.
    -   **Решение**: Мы используем `RegexRouter` для их упрощения.
        -   `"transforms.route.regex": "([^.]+)\\.([^.]+)\\.([^.]+)"`
        -   `"transforms.route.replacement": "$3"`
    -   **Результат**: Имя топика `taskflow.public.users` превращается в `users`. Это делает код потребителей (`consumers`) гораздо более чистым и простым для понимания.

---

### Шаг 3: Автоматическая инициализация коннектора (`DebeziumInitializer.java`)

Чтобы не создавать коннектор вручную каждый раз после старта Docker-контейнеров, мы автоматизировали этот процесс с помощью класса `DebeziumInitializer` в сервисе `TaskFlow`.

-   **Как это работает**:
    1.  При запуске приложения, `DebeziumInitializer` ожидает, пока API Debezium Connect (`http://debezium:8083`) станет доступным.
    2.  Затем он проверяет, существует ли уже коннектор с именем `taskflow-postgres-connector`.
    3.  Если коннектора нет, он считывает конфигурацию из файла `debezium-postgres-connector.json` и отправляет POST-запрос для его создания.
-   **Преимущество**: Система становится самодостаточной. После `docker-compose up` коннектор настраивается автоматически.

---

### Шаг 4: Обработка CDC-событий (`BusinessEntityConsumer.java`)

Это сердце нашего сервиса-обработчика `CdcConsumerService`. Здесь мы "ловим" и обрабатываем события, приходящие из Kafka.

-   **Прослушивание топиков**:
    -   С помощью аннотации `@KafkaListener(topics = "tasks", ...)` мы подписываемся на топики, имена которых мы ранее упростили (например, `tasks`, `users`).

-   **Логика обработки**:
    -   Все слушатели вызывают универсальный метод `handleEntityEvent`.
    -   **Ключевой момент**: Мы парсим JSON-сообщение от Debezium. Каждое событие содержит поле `"op"` (операция):
        -   `c` (create) и `r` (read) — создание или чтение из "снимка". Данные находятся в поле `after`.
        -   `u` (update) — обновление. Новые данные в `after`.
        -   `d` (delete) — удаление. Данные удалённой записи в `before`.
    -   Наш код анализирует `op` и вызывает соответствующий метод в `OpenSearchSyncService` — либо для индексации (`after`), либо для удаления (`before`).

-   **Важный технический нюанс — `TypeReference`**:
    -   Из-за "стирания типов" в Java, `objectMapper` не может напрямую десериализовать JSON в сложный generic-тип вроде `DebeziumEvent<Map<String, Object>>`. `TypeReference` — это специальный механизм из библиотеки Jackson, который позволяет "сохранить" полную информацию о типе во время выполнения и корректно распарсить входящее сообщение.

---

### Шаг 5: Синхронизация с OpenSearch (`OpenSearchSyncService.java`)

Этот сервис отвечает за финальный шаг — отправку данных в OpenSearch.

-   **Основной метод**: `indexEntityTyped(String entityType, Map<String, Object> entityData)`
    -   Это "умный" метод-маршрутизатор. В зависимости от `entityType` (`"users"`, `"tasks"` и т.д.), он направляет данные на дальнейшую обработку.

-   **Использование DTO и маппера**:
    -   **Почему это важно**: Вместо того чтобы работать напрямую с `Map<String, Object>`, что чревато ошибками, мы преобразуем эти данные в строго типизированные DTO: `UserIndex`, `TaskIndex`, `ProjectIndex`, `CommentIndex`.
    -   За это преобразование отвечает `IndexMapper` (используя MapStruct). Он автоматически мапит поля из `Map` в поля соответствующего DTO.
    -   **Преимущества**:
        1.  **Типобезопасность**: Компилятор проверяет типы данных.
        2.  **Чистый код**: Легко работать с объектами, а не с набором ключ-значение.
        3.  **Гибкость**: Мы можем добавлять в DTO вычисляемые поля (например, `fullName` у пользователя) или изменять имена полей для лучшего соответствия схеме индекса в OpenSearch.

-   **Индексация и удаление**:
    -   После маппинга в DTO, вызываются типизированные методы (`indexUser`, `indexTask` и т.д.) или `deleteEntity`.
    -   Эти методы используют `OpenSearchClient` для формирования и отправки запросов на индексацию или удаление документов в OpenSearch.

---

### Итоговый поток данных:

1.  `UPDATE` в таблице `tasks` в PostgreSQL.
2.  PostgreSQL записывает изменение в WAL.
3.  Debezium читает WAL и отправляет событие с `op: "u"` в Kafka-топик `tasks`.
4.  `BusinessEntityConsumer` получает событие.
5.  Код парсит событие, видит `op: "u"`, и передаёт данные из поля `after` в `OpenSearchSyncService`.
6.  `OpenSearchSyncService` мапит `Map` в `TaskIndex` DTO и индексирует документ в OpenSearch.
7.  Изменение мгновенно доступно для поиска.

---

### Как убедиться, что все работает:

1.  **Проверьте статус коннектора** (через UI на `localhost:8000` или командой):
    ```bash
    curl "http://localhost:8083/connectors/taskflow-postgres-connector/status"
    ```
    Убедитесь, что статус `RUNNING`.

2.  **Выполните поиск по проектам**:
    ```bash
    curl "http://localhost:8050/search/projects?query=mobile&status=ACTIVE"
    ```

3.  **Получите аналитику по задачам**:
    ```bash
    curl "http://localhost:8050/analytics/tasks/status"
    ``` 